{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1 - Keras入门 - 笑脸识别"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# from tensorflow.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "# from tensorflow.keras.utils.data_utils import get_file\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "import kt_utils\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = kt_utils.load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print(\"number of training examples = {}\".format(X_train.shape[0]))\n",
    "print(\"number of test examples = {}\".format(X_test.shape[0]))\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"Y_train shape: {}\".format(Y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"Y_test shape: {}\".format(Y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    \"\"\"\n",
    "    实现一个检测笑容的模型\n",
    "\n",
    "    Args:\n",
    "        input_shape: 输入数据的维度\n",
    "\n",
    "    Returns:\n",
    "        model 创建的Keras模型\n",
    "\n",
    "    \"\"\"\n",
    "    X_input = Input(shape=input_shape)\n",
    "\n",
    "    # 使用0填充：X_input的周围填充0\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # 对X使用CONV -> BN -> RELU块\n",
    "    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    # 最大池化层\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # 降维，矩阵转化为向量 + 全链接层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # 创建模型，创建一个模型的实体，可以用它来训练、测试。\n",
    "    model = Model(inputs=X_input, outputs=X, name='HappyModel')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From F:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 600 samples\n",
      "Epoch 1/40\n",
      "600/600 [==============================] - 4s 7ms/sample - loss: 0.8845 - acc: 0.6650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 0s 327us/sample - loss: 0.2567 - acc: 0.8783\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 0s 319us/sample - loss: 0.1699 - acc: 0.9400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 0s 312us/sample - loss: 0.1190 - acc: 0.9550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 0s 316us/sample - loss: 0.1124 - acc: 0.9617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 0s 321us/sample - loss: 0.1135 - acc: 0.9550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 0s 322us/sample - loss: 0.1610 - acc: 0.9467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 0s 326us/sample - loss: 0.0875 - acc: 0.9650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 0s 326us/sample - loss: 0.0657 - acc: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0584 - acc: 0.9867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 0s 328us/sample - loss: 0.0535 - acc: 0.9833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 0s 326us/sample - loss: 0.0453 - acc: 0.9867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 0s 337us/sample - loss: 0.0743 - acc: 0.9650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 0s 321us/sample - loss: 0.0429 - acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 0s 319us/sample - loss: 0.0384 - acc: 0.9933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 0s 311us/sample - loss: 0.0428 - acc: 0.9867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 0s 329us/sample - loss: 0.0375 - acc: 0.9883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 0s 332us/sample - loss: 0.0318 - acc: 0.9917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 0s 317us/sample - loss: 0.0503 - acc: 0.9817\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0495 - acc: 0.9883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 0s 319us/sample - loss: 0.0297 - acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 0s 309us/sample - loss: 0.0324 - acc: 0.9850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0379 - acc: 0.9883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0320 - acc: 0.9917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 0s 311us/sample - loss: 0.0276 - acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 0s 312us/sample - loss: 0.0208 - acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0266 - acc: 0.9883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0168 - acc: 0.9933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 0s 332us/sample - loss: 0.0123 - acc: 0.9983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 0s 317us/sample - loss: 0.0088 - acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0128 - acc: 0.9983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0094 - acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 0s 311us/sample - loss: 0.0111 - acc: 0.9983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 0s 326us/sample - loss: 0.0083 - acc: 0.9983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 0s 334us/sample - loss: 0.0153 - acc: 0.9933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 0s 322us/sample - loss: 0.0146 - acc: 0.9983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 0s 322us/sample - loss: 0.0114 - acc: 0.9967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 0s 311us/sample - loss: 0.0087 - acc: 0.9967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 0s 314us/sample - loss: 0.0080 - acc: 0.9983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 0s 332us/sample - loss: 0.0085 - acc: 0.9967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "150/150 [==============================] - 0s 851us/sample - loss: 0.1076 - acc: 0.9733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "误差值 = 0.10764151692390442\n",
      "准确度 = 0.9733333587646484\n"
     ]
    }
   ],
   "source": [
    "# 创建一个模型实例\n",
    "happy_model = HappyModel(X_train.shape[1:])\n",
    "# 编译模型\n",
    "happy_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# 训练模型\n",
    "happy_model.fit(x=X_train, y=Y_train, epochs=40, batch_size=64)\n",
    "# 评估模型\n",
    "preds = happy_model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
    "\n",
    "print(\"误差值 = {}\".format(preds[0]))\n",
    "print(\"准确度 = {}\".format(preds[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABGrUlEQVR4nO19eZwkV3HmF5l19909PTM990gaCQkJBJaFuAUySAjW8rI2i21sYfAKrfGubIM5LNYs2NharxFgm2UtX2g5zGHAYAzC2gGBQUIXEkKj+xhJo7m7u7qr68zKfPtH1WQcM93T0sxUy1vv+/3mN1H9Xr18+TKzMuJFxBfknIOHh8f//whWegIeHh69gX/YPTz6BP5h9/DoE/iH3cOjT+Afdg+PPoF/2D08+gTH9LAT0UVEdD8RPURE7zlek/Lw8Dj+oKfrZyeiEMADAF4FYBeAWwH8onPunuM3PQ8Pj+OFzDF891wADznnHgEAIvocgEsALPqwh0HGZYIsAKAV2x8ZoWQEWuEIQ5aJRJtLVL92uyna4iWm/nQDieS8skI2yyjmSKSPFYohMkFkvif6Ou4YkF4PedZEeogk4dZYLEEc67VyYpTAjBEGR14fMgeLE+6XmJeGk33l18yxIL+XLNGm1j5U3bIZXv9QN0FdazHfTC6reuXEGGTuv0TcZ1Gk76t2u53KccJyYNYqm+XjFTJ5PYb4XrPVEmPr+yPI8MnlciXVFoadMWu1OTSbNbvKAI7tYV8P4AnxeReAFyz1hUyQxdqRLQCAx+fNlY15AYLCgGoaGuOTzOe5H0UN1e/g/odSuR3N6vEDHiNIeEEP12wWt2ycK4pPa8RX1qp+mZAvRCanL9jwAF/YVcV9+sgZ/rFybV6DfG5I9WuRuKnMdGtNPreKWOOZ6QXVLyJeu8GsXoOB0pFv2kxG3y6VGt/4tXZLtbWzPLF2hscIsvo+TFpifWp6HtTm+RNyomVc9ZucGOOWEWgkPEdX5/Wd3DSluk2N8/XMDhRVW7NVT+V9e/V9tX9mOpXnKwdTOV/Qa7V+LR/v1NVbVdvBajmVH330UR57eq/qNzDJ571l03NU2+DIyQCAG779SSyGY3nYj/TrcdgrgYguA3AZAITBsRzOw8PjWHAsT98uABvF5w0AdttOzrlrAFwDAIVsyaXqDOk3AaiWiklDvw0bc/xLG4yJv1fKql+7OcPD2d8ix28yd8TfqcNh1VatBMg5tk2/xc2EwRKf99SEHr80wG/zefEiDo26Xxdv0WpFa0jygg4Os+o4X9FjdLZcOkgS/dYXmqlSkaNIj9Fsis+hUfEb4vqW+K2ctPRaKVvDaFV6HVmmQKvSTlyLaq2m2vJCfXbCzLMqckuoz/VYt8XC5KzX9H0bZLhvJsPn2WpprTOq8+e5tm5LxNq5jLTztE2Syw4IWWsfhULnszVB1FwXbTk6bgWwjYi2ElEOwBsBfO0YxvPw8DiBeNpvdudcm4h+E8C30Nkx+Vvn3I7jNjMPD4/jimMyop1z3wDwjeM0Fw8PjxOInu6YOZcgaXd3NhNt1waJ2IkOm6otarIdVtnPu59RtF/1I1rK3bY8Ox0QY7icaiFhmzuqckOi7eYk5M9F7WXBUL4tZL0Gg0X+LHfEWw3j1qry51pGn3M2Fi6eQb68z57YqPrFEY/fjvTahBme/74nd6Vyo6FtzUYo3E5tbYuTtDcbddFgdtwzwqZ2+roThHtJfM8Zt2osbPF8qG/phSYfuxSKMRLd72CVd9nDQLvl5qZ5lz0x11pe+4I453qkx1ho8v0yX9Pn6cQehBPzj2N9nnnh5WlHev6Z3CAA45o28OGyHh59Av+we3j0CXqrxgM4pJGSjR6LhRqflHWT0JxiGWZ1mNq+XFV9eTjchSaPt4TrTbhW4ubibrlMRs83Et8rDIvvwKhzMZsX2aZWK8vTFdFPuJqMG3Eumk/lwYEx1Vae5nlMTXEwSGDcOj+6++5UHhrQgVAytE+e80LbqLBSLbbhgIvAOe3+ciLgJpPVdlNGuHGHJtelcmgClYpDfG7TMzqYZXaB18reE6UCu8BklFwz1tc9VxxN5XxJr7eMuMxkeX0a7Z26X8jn2Xb6Whxyiy7l9vVvdg+PPoF/2D08+gT+Yffw6BP01GaPnUOlmzUUWDs3YFslsNlPCqLRafeGIxOKebwhx1f7BdqmDoVrqGSyq1otdsHU6vOqbTgvbL4G26+1ql6QuD3IbQvGBhbrmhlhw9+6cdx0IZWTtrZziXjMubk5Hs8kwpyymRM6bCitE6l0zaawQ+dMwsyS2YmLQX8nEckurUiHywZibyXM8boNjkzofiLUdWRMn+f+Pex6s+7HVoPPbdWqVak8PDys+mXy/HnVmk2qrSpcccVBHj8xLsByhc9taPyw9L6jwr/ZPTz6BP5h9/DoE/RUjU+SGI1aR3V1sclwkmoxLanHC5wItV2SLiwxvogADDCnmmLxG1prarVvIOLvNZ1Wn6siki0U7qXybEH12zO7J5VtJFi1zqre/grPa/WozgGfLR9geVbnaG89+SQeb4HnHxZ0ptXcPGcZWrfcYFGYCYKcoZTX5zJf1Rl3GmLtFs04BKI2q7Tzda3eFkqsuo+JKMLJ1TqiMF/g7+3aXVVtAyPsppPrC2gCD9fmeziT1e61VePrUzkJ9DqWBljFL5T4miWRfg6iiN2qSduYZekae9ebh0ffwz/sHh59gh5Tx1CqdjqqmSahmv1bqDUZcIKFS8y5gNXzdqRV9Zl53oEvZrQ6OiJ2xYvDvLN798P3qX6bNrAKevCANiEkbdeBaT5WLafnKHftR0ZGVduePWwmjAyz+l8ul1U/mXNhE0TkDryMLAsNSRwtEmnXaVxsp173m6+x2t3O6Vs6P8jzl1FzAyW9G99oCvU51nOU85LnBQA1keSTy/GO/kROmysyT2hoaFS1xTICsMiRiNY0khGW1sRM13+JZ8e/2T08+gT+Yffw6BP4h93Do0/QU5udCDiUm5+Y5H44Yb+SyYh7JkJF79nfTJFtlmh+7zyx3dgy9lVFZFft3sOZVydtOUn1awp3XrGkL2Ei7FzBhYHGQln1G8yyXVoy2Wb5goh+q7EtWzd00TLjq16vq7aFBT742JjJ8pIQHPVBZIkkj5wFR9blKmzsmpmHc2w7F4o8j3xeR7g1RCRfvanHmK+KCMCGbktivhYLYu8glzcuxVDwwceGnFPWPxDzLZlsxKQlIhtnNXHL0MjqzljJ4hGJ/s3u4dEn8A+7h0efoKdqfEABisWO6mcTJ5QLppeTerpQ/HR6GSVnvXUnNSNW0yomwSVQLipue+yxx1S/iVWsgp72rFNU2xVvexsfq8KqpJ1HEkquPW1SiSA/JIIM4sn9mtThzz/xiVSentFJPVu3nJbKkpNdugYBwEl6OsOTjmiZkZTC7LOKf7bIEXSFIXbDtU0JpvI8V+dpNrS5sn8/q8xR2963LKuEH5MwI9us+25IJOWUSsLsy+r1mCvzHEeaq1VbpWumJV6N9/Dw8A+7h0efwD/sHh59gh5nvSWoHarFZdxrigv8+PJGnhiQCJfFKt0m7PnIlJV2olrtgVndVhrkz6FYhJO26KqfH/nwh3kabROm2uAMNifquVmXTCLs9MjpBScR+joibN7s1tNVv3/62rdS+aqrrlJt3/72t1P50D5Nd3DVLy/apG0PAE4yjUpeSmio3QhzLkUR7psXNnBoyDxqVbaxH358p2oLBHmkLcEt0Y75nrDEJFFTluDW9QjknGXtg2xWk3i2WjzGnMhaBIBioXPd4/Yx2OxE9LdEtJ+I7hZ/Gyei64nowe7/SzhSPTw8nglYjhr/SQAXmb+9B8B259w2ANu7nz08PJ7BOKoa75z7HhFtMX++BMD5XflaADcAePdRx4JD3OUyd864MI725WcCnFwu6Raxy8iqLxmCCplRlQ30WY+OsDlwYNfOVH7/+9+v+kn3TG2uotrabaly0hFlC9sWiwivRJRlHhjSamVF8Mn92qWXq7abb775iMeyLkBJaydLHgNATfgAnS31LCFMg4A0H/zgoHC9FSShhjYnqoJMpSJ49wBjXixxo8oxFxZ0BJ11t0nITMChITl/U+Ipy/OfmdFznBzvmMfOLe6ufLobdGucc3s6g7s9AFYfpb+Hh8cK44Rv0BHRZQAu63460Yfz8PBYBE/3Yd9HRFPOuT1ENAVg/2IdnXPXALgGAIgC59KQKUtUcIJpoJcJtZlrIsv0co2k0mG7w4p0Qe8wE7EKnsnppIpAWAbnnveCVJ4w5BJSXWyb6qmSKEJymLXtLrIY4zD+OFHKaaHBZsLwgCZkKKiPeoxQMFvIRJiGUWdzgsDDRp05MeeMmL7JI0Eg7qWMKLMEAIUB3o3Piai5JNHXtiL4+hrVGdUWKIINc0+QnvMhFIt6rVSil6lW62K+R+Q1Cws6iSppifkb3sNds53oxlZ78SSyp6vGfw3ApV35UgBffZrjeHh49AjLcb39PYCbAJxGRLuI6K0ArgLwKiJ6EMCrup89PDyewVjObvwvLtJ0wXGei4eHxwlEjwkn/w0gka4yuzxPveTOUnCm9FEsbLdTTzs5lRtNzWNeHGBbzkad5YXN3sqItoY+1ux8OZUnp9artnr9yFlqNlNx9uB0KltX1gWveGkq33777Yv2a9R4jVstE1kWsW27VP6b9DaNjGh+fOlWlOdycLqs+tl5LR9HvidsuS05vnXDjWWO/BjK/ZcOpFtVz7e+0ClR5ZLF9758bLyHR5/AP+weHn2CnqvxqVr1DGWoIEiXiVajAuLlip/m/FUEmeFFL8+xWlwsioquRo1vNpm84jAyCBlBJ6rCHnxYE2AMTbK6a02BjHRRiYqpNtKuLSqYTk9Pq7b1ayZT+T4xD8mtDgD1aeG1NapvIBbZLRGiIclCwkCvx8iIcJGK+Wcy5lykC9NE+clrZlXrJDkyUYmNFJTfs9VwpYovo+kO49EX18LZElj1cncwT17h4dH38A+7h0efwD/sHh59gt7a7BQiyHbszbg1e5TOJxLStjLujWBx11si3Cy0lBEpj2TsLnIcXplNtN2VDfnYWzduEoNoO7cpuNEzpgRyIsM3G/y9sTWbVL+FFpMrDGgzF7EMXQ7YzZe09Tkng4J7flxnxG3Ln5HKN/7w1lTOZsqqHzUWzwZb5hIjETZ7rqhDTCW5R0bYzbWGXvuC3EQy16yY5zEnh/V51iO+FjLTrWnCmCORMRnk9T0X5vhzkOV+ti6eQ3nROSI+FNZ8/LPePDw8/o3BP+weHn2C3pZ/AoG67iwyh3ZY3GXQUwi3U0CWeIJVJ1IRV8uPrJPuHxtlJbPDJlaNpnKzoV1vkuDAqnqVKvdtRqzS53L6d31A8JvZyLj5Gqv4e2YfTOUdO3aofuOr1qTyRa/+OdXWdFwienxclE1+QrsAjzesK1Kut4xcGxjQ6rjM/LNjjI0xAcbosDabSjGr+HKM+brOhisJ/v3QaNpZkSHYqrFZYK+tzAxdzMI5zFsn4N/sHh59Av+we3j0CXocQecQdqPGIhM9Rup3Z6mkBO53eISRGO8wzjUe08k2p9WyIOAlcYkeQ5EYLKW6KyIO/Xsq55xk9S57UBfHFsszNjah+n3r+n9J5f/7rX9SbSVB/fzs009N5c1r16p+m0/Zkso/+P73Vdu9Dz7Ac4xYHX/BuS9S/YZKPP+7bvuOanvOC7jv1q3bUrlW15x5b/mVX07l332f5tpbgrVZQySFhIklbxAUzuLahiYCLVvg6zlY0ip+LssTKRV0W0ZcqMo8q+qDprpuNsfjZzLGgyJMQmnaUcYmwhwb/Jvdw6NP4B92D48+gX/YPTz6BL212d3h7qZjgSorZFCvazLHxWjTyTgxMiJsS9p4ANBose0WLhHdJc/Q7h0kgniwVrPc4nIvgW28f/3ejarfvp33p/IFLzpHtVUqIjIxPshyYUr1y+TZ9hwY1a6m005hMotCnrPGpg9qe7u0id1O64b1nkBSZ1t/08k83gvPOUP1u/m6fxSf7LvnqRNK2PtLZrNJFyOZjEaZjWfvq4EMz6NkuO1LoqRUNcfnXHWLk0jYe6IhSCIDEU03Z/jrjxX+ze7h0SfwD7uHR5+gp2q8Q4Io6RAlUKATFlxSEx8W/w1aPcpq5ZhxgzRFtc3dsUnul0kcgrfbqurS5yU54QCARPXNWKqYNplGzP+wyMCQTYH9d1+nmn798v+UyoU8u9BO3aRV8HHi+e946C7Vdutt96Ty6BDP8fTTX676ZVqsfq5Zt021XXfdJ1K5NLQhlW+6407VT3qXrv6jD0CD12AgYLKNZk2bArWZ3fzhaRKCSBddparNt3abr6Gkx48M37ugr8doXt9XxZD7Wv64IBLXWiTFDI5os2ZgkO9bBDY5iu+RZp0jIBtVbeYdK/yb3cOjT+Afdg+PPoF/2D08+gQ9Jq8IgK7r4jBSh0S6NAyxgCgqJjOBhoeHVb8FQYSQq2rXR1tkgBHJml+6Hzm28WwdNQTCNpdZb9YNR4sTMmRFRtWn/1jbuVe+57dTWbr5Kgtl1e+2+25L5Uxe24b372N3zdgBtiEVGQaAhQrPcXKVHkNmsO167KFUftlL3qz6Ta3bksqj69aptsIgX8+GCGedPziv+r3olRenMn1Zh+0+HcSJXntJpinlpKH3YwqC4LPV0nZ/GPL9uBSR5FJ/X6o+nyTJjMR1f/pc9kfGcso/bSSi7xDRvUS0g4iu6P59nIiuJ6IHu/+PHW0sDw+PlcNy1Pg2gHc4504HcB6AtxPRGQDeA2C7c24bgO3dzx4eHs9QLKfW2x4Ae7pyhYjuBbAewCUAzu92uxbADQDevdRYFATIFztuDRvpFMXSlaX14mzIKuGq0UnRYDjTW2KM0GQW5VhtCwUvmXWDtCN2d5AtQwx2ybQNsYWeiOAUM+WQJ4dYAdq0RWezHTywJ5WLRSaoGBxdpfq9/g2XpvLu3btV22hRlFMS0V7Dk/pYtZj52os57QY9/fnnpvLJp25OZXKDqt+QKCU9ODiq2uTa5dscyVdaq82J804Tbj/3XtW2aNijgbxd2k6rvoHIMGuKcshkrksiuQGD0LQJtZ50G4n7J5MVJBTGkovk/W6OHQufo0y0DJMjl4N+unhKG3REtAXA8wDcDGBN94fg0A/C6uM6Mw8Pj+OKZW/QEdEggC8B+C3n3Pzh+eKLfu8yAJd1PhzfwogeHh7Lx7Le7ESURedB/4xz7svdP+8joqlu+xSA/Uf6rnPuGufcOc65cyjwD7uHx0rhqG926rzC/wbAvc65q0XT1wBcCuCq7v9fPepYONyGPYR2IENM9Y+CdGMsxU7jMmLsrPlhacrPbLtZ94ac32EllaUNtch5WAShXuIhwXry0gvfoNpuuvMHqSxt4A0bNqh+kQjj3bxZ702sW80ZZrlBtrErFR2mKl2Ygak9NprnrK9azC61QkmvFQmX0eTkpGo7OMN2uqxttnrNGtXvX2/9YSpnDTNLFC+eObYYrMbZEkw7TpQ8tntGzQqHqVq++kASQpq6eHIceW/aem6S4NLec/KzzMyzmZvHiuWo8S8G8CsAfkJEd3b/9nvoPORfIKK3AngcwC8c15l5eHgcVyxnN/77WJy59oLjOx0PD48ThZ5G0CXOpWqQVeeXUs8lpNpkM5AiUa7WcEUqsoJERFkdRi6RtBZtcyTUqkQsnd2sFOcyMjqqmoayfOy/+aLOeludn0nl8XXs8rJrNT7Mjo9qVXPKl+PyEb9HhoNcqqODAyOqbeej96XywACr9AWnI+1GxblZlVNez8UIJABg47NO4ba2IYtc5iawhL0n2jF/jtqibJZZ05Eiq9nzhlO+XV+cy12ep4z0HF6l3aVSVbfkGPV6dMR+lr/+WJV6Hxvv4dEn8A+7h0efoMccdA7oqmqR2Q0NEhlFpH+DIhHx1pCaXUarVHPTHP3WbpidYzFmIlQvIsNVJ3//jGVBVFU9F+vnxG5/CK0iF4b484/vvlW1/dSzWE1eEOp5Pj+k+i00ua1a0TxloTBDvv+dG1L5xS86X/UrCZ70/ICOoDvzjOek8je/9PlUPvmMU1S/qMlJLWFRq5xy9zkM2YSqzJdVv2RGVNSFxrKVePFFSVYBAHXBUx8I8pGcSVQZnmSCkIm2TtaZ3XfkHXcAaER8vDWr2XMxtm6r6jc0yuPLex0A8uI+zgh++cZx3o33b3YPjz6Bf9g9PPoE/mH38OgT9NhmT5B0SSSsPeYkyeRh7jC2gWs1joiyJADSnlrStRcsbpfrOm1mjorHXNTkOsxFxMtaq0+rllbEduMje7Tb7N3vujyVn9i9K5Ul1zwAuJYgxWzqMQ7s5ZLItYMcwdwQEW0AUBG27MKsjnS+8SbeSzhNuAD37XxA9RsUbrm20/snAdiWrQnSj2JT9wuJ12q5+RYW8nv2uudEdmJBZELmc3qPIStcZaEpCjAisg6tay8U7rHJVRy9mC3oiMKsIPPIhMb1Ns37Lo3G8c10k/Bvdg+PPoF/2D08+gQ9L9l8KEItOIz8QajIiXHLiWQSqWK1mtq9JksxU1b/jpHwyCiV3iS7LBW1RXKOS/DMyd/QVlOPN1Nnl9SWKe2Wq9V4LjKxxJorUYtNmSjSCS7N6X2pPLWWiTLuuvNHql9hnOfx+OOPq7YnGzyP8Uisj1nvfbseTeWBiVHV5sQ1yxb4Wk9t3qj6nffiV+JYQYIspN3SZk1T8MnFIrGmOKKJOIqOXWODRc2wVq6Pp7JNYpEuxqEhdpE68x6lArs3a1VTLlqQsCSC9aJemVH9np6Rw/Bvdg+PPoF/2D08+gT+Yffw6BP02GZnJMZWzoliW2duO1m1FUrsrpH13KzdPyO40KcrNdXWCsTxhF0eGqqsdrKUS03ALbF0tDhH+MFZtsOyZvjdgvM9FC7AVZPatq83OCy4WtPhstMifDYssK2596B2ve24md1rAybLa3yEv3fHA1xLLptoW3Ndk4911upx1VZv8F5CYWA0lXM5TbZxfEp48xhRW1/3dltkOAY8f1miGQByguwkO6BdY0Mi5NnOt1RiW1yOGYR6/LpwnyaxnuOC47XSrjcd+nus8G92D48+gX/YPTz6BD1V4wmETJdEYvVm7d548yUXpvL68VHVlimx6rd7L6ujDz72qOp334M7U3mwpFXTJ0Sm0UI8m8ou0iF0OUGK2YLJnFOlpJcgz3RsXjin1bmFBVbT9ofabfb2K/8wlRvzfJ5f++z/Uv3ihN1J9YZ2z5SbrP7PTTMP/ct/6qdVv5PHeI4H5rS7qhXzHCcb7NZa/8IXqH4/+sG3U7mYM9xvoo5yU2Qglme12XE8IIlKKNIRaPIKShNteEC73koDsiSYKbskSOkC0mZIqcCPkFTja009DxeJ+8o8dZFQ113AY5Az0XTH6Hvzb3YPjz6Bf9g9PPoEPVXjgzDA4Ehnp/NPf+u3VdvoEE8lyGtiAalOT05wUsK2005S/c4+p5zK137m86ptYlSo1m1W8aO6VpV0osPyePEOB6vSDjaphz/LpB5A7/4PDY2m8v4ZrfqODPIOsCwTBQAPPMDJKs8780WpfOOt/6r6/czFF6XyqSVdDTc3zGvVELxt73vn76l+Z5/B65/Jjao2uWm9UGUyiGTPHpxIHM5lyBPJF2QkpjbDJN+bTaap19nMKRb0vRlISu6sGL9tSkg1F6cvd5GguI74WgeGxCXBsXku/Jvdw6NP4B92D48+gX/YPTz6BD212adWr8YVl72tI2/UvNoyEoyM3dUSpH6yFm5Iut9Zz35hKr//feeotr/6qw+nsuI0b+jstb1796ayKiP9VEDCtnL69zSQrhUToSejs1qRJODUl6ktSg+HgbYhx0UZ5b/++0+n8gev0uWQc1Nchilvyi1/4s8+msoDBXaR3r1Tu/lOP02UXw41aWUsXE9xwjbpxz72MZxIWHs7FjUCEjEP20/a0daez+UF/76552JxCRuC996Oocpt2dJhIsjSiei6rCHFbBrO/aeKo77ZiahARLcQ0Y+JaAcRfaD793Eiup6IHuz+P3a0sTw8PFYOy1HjmwBe6Zx7LoCzAVxEROcBeA+A7c65bQC2dz97eHg8Q7GcWm8OwKHMi2z3nwNwCYDzu3+/FsANAN691FgDgwM477zzOh/ampstWRCqr0k2yAp1uiVU8MQZNVuoQOvX6Mqnb3jjL6Xy575wbSrveqys+o2vZtKIfXu12qpdJou7QWgJj51U1a16LiPBaoK7fPNW7WIs72OeueLIOtUmk3BWCR7zy9/5h6pbTkz/5DVTqu2ks05P5ZIgZPjLqz+q+t10w1dSOQj1ScsKuE6s1Q9v0SQax8zIAChTqVTQEW5DwqXWaorSYS3t9gxCbrM0cIGYZDXUbtBijs0XnfSk1XiZwNWo6mNLl9rk2Ggqn33G8/UYIjpwz0Htwty3fxeOhuXWZw+7FVz3A7jeOXczgDXOuT0A0P1/9RJDeHh4rDCW9bA752Ln3NkANgA4l4jOXO4BiOgyIrqNiG4rzx3/uGgPD4/l4Sm53pxzZXTU9YsA7COiKQDo/r9/ke9c45w7xzl3zujIyJG6eHh49ABHtdmJaBJA5JwrE1ERwM8A+B8AvgbgUgBXdf//6tHHCpDPdUJVZ+YfVm1JzDZOSNoWl7ZyJPjJM0Xt7mlVBXlFS9swk2MTqfzSl7KL7rOPf0n1k2456/qQNlmcLJPf29jvgXCVWSIE6Yprxfw7/LILLlL9/s/H2Y1oy/8OCqKIy9/6qlR+57s+oPp99CN/nsoLxn03OcU15x64645UNjwcGBtlyy2b0deiXN7NbSVtRx9vkLCprTtzIC+OLfZ+KhWdcRhFSxCIioxJMuGytQUeR7rXclkdxlxrSOJLfd0HxJTHirzI42vXq371GpOWyNBfAGg0Om65yoLeC5NYjp99CsC1RBSiowl8wTn3dSK6CcAXiOitAB4H8AvLGMvDw2OFsJzd+LsAPO8If58GcMGJmJSHh8fxR08j6Or1Ku665xYAQFDTavCqVYKb20SuRS2OHMoKrSwINEFFLHTmKNL8Xa0FJqwYHWT3mgu0i6Qg1KPxIa1uSfWr3ma1tbKgXXQaWq0cFBlrNpCqWiuncihcN9msJsCoiag/yus5bnvWNp6XyDb76Pv/QPXb8f3vp/JzLnytnkidVclTNnKZ5nq9rLo1M3ydDhzYp9pygis+l2HV9/vfvUn1e8nLX5PKSTir2kj6IpU9ZK5ZIDImzaI2WjzHap1dXgsVTdgxL8poFU3Uoywhnm1oNZ4yPMd2xHJMevx8hs2tVlOXYo4S7lsQ4w2vGlX9Wo4JN2pP6Ou+erJjetUbuty0hI+N9/DoE/iH3cOjT9BTNT5q1vHkw3d25Fm9Gxo/69mpvHHtJtVWrbKaM73vQCqXhrWqPrGBdy9jE5m1UGUf/6AoxTMyqHdNy0JVLRlKYbmjmgjesKahtG45VrMtZXFJ7A4Xi/p7kj66WhXr09bnuXETR8bt2693XzedfFoqf/MrX07li179etVv6gkmrMhXtApODW6rC9X32cJEAIB7fvId/pDXu/GlEp9bJBI4XPyE6rf96+9K5Xe9+xrVdusOeW5SPdUujkiQm5TMmjZFJF9bvNpsNda24MlrZkwiDLHq3qjrZJR6U1BEi+ueLWoTMxHmZ8uE6LUEOUYGiyfkSHeIpf/OZDqP8lL05/7N7uHRJ/APu4dHn8A/7B4efYKe2uzZMMTUaCeS7a4nNOf72poogWOygmb2c98f37cjlUtFHX67qXIWyyfp8H0SdtGCyHgq5rT9t7/F9vFASdvzwzm23Zwos1TNaFcKhFlXDLWrZqjE+wChydrLCmKLqM12nTNmWFFkRmX27VVtc1U+n8ww95tZ0OWf1m7l6Lddt/1EtQUTPOdWgw+eRDq3ITPKFAbZUN9KUcxrMiQyw6K2Xu9Gwm7Qc56j1+riV781lZ+ks1O5vvfbqt/nPs8kHQ1b9qvFdi61+Fwc6WPF4qLJ7wBAXmbSkbbZYxF5V63xvkI+0tc2IzaRqnP6WiwsPJnKYYPnH0favdYQmYXtWO/j5LOd+4po8fe3f7N7ePQJ/MPu4dEn6KkaX64s4J+/3eEvL5kjDw+xSujyuvHxJzmpxTVYHd+4WZM6UJkjsOZ33a/aghz/rs1XWI0q5LULIwjY3WPdGIUiq3Mt4Q7LZLTq6ARP3tCQMQVEUohVueZEokMhz9+z/PLSlWVde63kyKQaCwsL+g+i2ukupyPXkl08/7E1rGbPx1qNj9sieswkyVDC65MTbjk7j8FhHv+Cf3e5alsV/lMqX3nNK1L5c3/3SdXvw4Izb1jw7QPA1R/5eCo/dF85lUOn13QgENVYC+aeENfCVolttvheqtZ4HclUvHWCRCNjiE9aNeHSrbApUDZm3pAoixa0Dfd8PH9IwGLwb3YPjz6Bf9g9PPoE/mH38OgT9NRmD4kwlOsccv16nZi/bjUTRM5DhzI2RBbSzv3sahrecLrqt3GADcdWU9uh+YDtrqIgxxjMaRdMS7jemgVTr6vGdlh1gfsFsXYnrRnm/YexYe0ezBCP2WjrzKhI8JoviHnkjI23ed2WVI4PaoKgujCeh0RZ4hjGBVhgW3nTWlPbLOJ55SaY9IMyuszx7T++MZXPeNZpqi10RybpIGPck+PPYUaTXBzcxbZseSdn6c3M6szqvAg/rS/oNX3Lm9+cyodCSgEgSfT98V+uuJnHiPVazVTY3Xvu2ZpqMRbXRoa9No3N3h4Q2Y7GFo/FtZZspXUTVtue5mstzwUAMt1HmZZg8PRvdg+PPoF/2D08+gQ9VeNHRoZx4YUXAgBWr9bqEDkRPdbSEWmHEvMB4L6Ep/zw/Xerfq0pzgY7Y+gU1ZZfxZFrM2V2r+01arBUjyxXWBwdubzPYS46EXFl1S35vVrNjC/IGgYLbHbccuvjqt/endensqWol3x9Z57JUYQLFZPl1WTVsW3UygnBnZ8UeN3qLd1vfppV4YZRn4dKrApLQglKLL+8O6IMAJUqX5u2YxfXuvWW747PrTKvXWN797IrS17P4UE9xs6Hy6k8PqWzLm/85tdT+bznXKraEpH1Vp3njMz82KTuJ66LzXpDKNzCNV7H2NxXTrhVk0S3LZXtdgj+ze7h0SfwD7uHR5+gp2o8UZCquPv2acKEqMGqamZ0rWrbsGFLKl90wcX8nUDv7K4/hXfncwtanWuLXfd5sWtaXtAkGoq22lTNbIror0iU87Hqp1Rb7RgFwSc3b3j42oImu1xhKuY/e4emgf7pV/AOv3MmoUOoqjK67p577lD9Ttq6JZXzJUPSIZI7ymWOmrvtDm02SZrmybFx1dYWiTBSxcya94tcn3xeE0+MjfB9kBcUzhl9ypifF96DrPYYhCIyTkaX5bL6nGcrD6ZyjTQhyNTanancbulr3RaEJq06cxFWzblI6mqbHNWIeQ1kFCWMCVgQlN9t4wEql8sADjc9Jfyb3cOjT+Afdg+PPoF/2D08+gQ9tdmDIECx61KamdV20YGdnMA/27xPtT3nLC5du/lUdicNDmr7LCsyqOZbJpNrjiPv2tKMdtqmrgq++eHisGqDKDfVmmdbtmXcSfKzJEPsjM92Opnazo89/EgqX/DCt6Ty3374XNVvX8RRbY15vffhxJ5Drck25P0P3qv6HTjImYQB6ci1/Qd4vwABj7drryZd+J13MlkkmTJUQU1w2wubXXK3A8CA4JcPDQHG8BS3led5HtMHDTe64++1DTmnLOE1O8v3xPiovnfihK91CG1vf+bav0vlyGQq/u//fUsqZwqLZ/etWytcuoF2k4VijjkRYdk0+z1tWR4s0edZbXds9cRZZyxj2W/2btnmO4jo693P40R0PRE92P1/7GhjeHh4rByeihp/BQD5engPgO3OuW0Atnc/e3h4PEOxLDWeiDYAeC2ADwH4ne6fLwFwfle+Fp1Szu9eapwgzGKg61YbMm4nrGX1ZZ0p7ZwtclupxKqSjRqqlzniyhlyAicinSYmR1P533cj+g7hsT2sft34452qrSCOVyjwGLYiaCYvVNqM/j0tL/B579ixQ7VJfvzv/vAH3BCv0/0WmFwhMJz1QZbPM2iz6+1XLv151e+P/vBDqWwrsM7OsolSKPEYL33Fq1S/4WFWfa3Lx4mkFqmMJqFWM+X3IqOCD+f5GlYz/L3pmT2qX9Lm9bbln0olVtelSm9NKMhkFEMA0ojZ5My29T13xeVvSOX9Iknr/3zmG6qfnJflfC+UROmzLJtymdhGX/K1aDR0xCIOmQZLBNIt983+UQDvApQBusY5twcAuv+vPsL3PDw8niE46sNORK8DsN85d/vTOQARXUZEtxHRbXPzixed8/DwOLFYjhr/YgA/S0QXAygAGCaiTwPYR0RTzrk9RDQFYP+RvuycuwbANQBw2sknL75V6OHhcUKxnPrs7wXwXgAgovMBvNM59yYi+p8ALgVwVff/rx5trKjVxO7HOmGJjzyoQy/jiO2pdavWqLZgkO3SOZFZNJjTLqOwwDaNa2jXR1OUyR0UhJbrRjeqfnlRi+wnw1OqLSfs49IAz3duTmssQcC/ac2adgF+/6bvpnLFlA0uFtgGLgliyrGxrbrfQR4/G5raZsKjVJ4TGVSmDPZ73vvfUnn3Hp1V99CDTNb5/LOel8qFIe1wccIajy3BIo6czSbdTAAQCQ7/wBickajPNxGylZgzdnlFuKiGR7QLMBIEIW1BnBEb11UrEm7FtqndN897MpHZJwqFK3V8ktfnN694k+r35S+wYpwN9PhFEXacla43p+cYiWNFJlOx0d2TSpLj4Ho7Aq4C8CoiehDAq7qfPTw8nqF4SkE1zrkb0Nl1h3NuGsAFS/X38PB45qCnEXSVuTnc8I1/BgAMTGpVPROwmj2z+0HVNjTKUXPShSEz1ACgPMNRYbZMT1O4+gaGmRiiXtVEGZJbbmhQq62F4mgqy4yybEGfy++/j/nPzzxN8+S1hUswIM35/sD9D6Xyxk2c8TUzrdX9fGFVKjca2u3XFOGBWZHZZUsUS1KNk07S/PtrBVd8IjjwHQx/nFBpD8v8E1lZ0r3WjrRqCmGu5LN6PdqiNFTT8RpYrv+ZMptRRNqNGInjyXlIrkEAcMIkfHznA6pt7iDPw7rNXJbHaUhFOdTzeMMvvyyVP/k3X1FtTVFWy4laX3aOmayMNtT8iGOrOuZotarNRgkfG+/h0SfwD7uHR5+gt2p8rYrv3t7Zldxw6k+ptmzC6uLzQ/0bNDch6KOHWDVdMCpLo8mqno2kCoWamSnyae+6+x7Vb3CY1WcypZsKYrWyw6zOFau6YuzJ23gXv7JguN9EZU4KyqptfJQTXM59Pq/PN294RPV70XO38PjYqdqSiOcliRwiMnx3QqXNZrVXQ65dLK5FXmvZSNqCoMJwokmVn4R3Im5q8wqismrGqPGt4Fmp3Ih5HZttvaOfiF3rak2XqMpleT3ihOebyUyofrKU1cSYVsFzgnq8USmrtsKgiGbMs2qdMZGNNZGw9J/e8h9U2598kKMZM4KZo1jQj6cT1zCAnuPEZIc3b99unUQm4d/sHh59Av+we3j0CfzD7uHRJ+ipzY4EiBsdu+MHonQQAJw5yXZu9jmnqjYHtsmkDZw0dZQcCVdco6ZdatJNFMhovY2aX37Ho+zKCs0YmdWjqTwE5hbfW9G2fQjO2qvUtQ0pXU8bNugIvfIsH/uyt/1qKr/p9S9R/X71Zznr67kXnKHaIMoptSJ288WJ3jsgUQ4qa6LaKhUeQ2YZWvLMnDiW5TGXXPTSzTdj8iOGIUplZTU5xs9d+qlUruJknruJYhscGE3lONbnmRX89XKfwpJbZrKiJNig3sOQLl67VoEkKhHu3bp7UvUrlPg8m1XtLr3y/b/H8pVX8nEDUzo6w3MuDGpe+uHRTt9MZvH3t3+ze3j0CfzD7uHRJ+ipGr9mYhK/c8kbOx+aWkWeCUX10XHN/RaItrgtVUcdYZTURUVQS2whI8Ga3LZqta4m+5ObuZpnktFc6HMVNhs++glWs3/1VzVRwYBw7R1s6yg/GRV1YH9ZtU1NcbLHw4+yu81lNFXAdd/iCCyrxjdb7H7MhFId1fNQ3zHRdTI6S6ruNkquJQgUbGBckGf1X45fNFx1UcQ8eXfc8k3VtuHkn03l723/fCrvm9f8hfI8jccVDVFqSarjskQXAOTzrJ5HkV4POX9L0kEywUiUJms09Hq7hM2XgdyoaktCHvPsn35uKt90449Uv0aT13/tRn1PjI93VPxMRkfWSfg3u4dHn8A/7B4efQL/sHt49Al6arO3kwjTjQ4nuSWeaDU49JWMWwQNtrHzef59Wqjbksf82dqXOx99LJWfLPPfD9b0saoNtinzhhzx4pdtTuUHbv7nVJ6b0S7A8y/8jVT++J/+tmorFtk2fHKX5nzfsJGz5zav52y5qTWvVv2ix5jkd3pGE3eGkXB5iVp40rUE6BDWqG1DadlOL+R4fST5AwA0xefAuHxaDbZRk4TbMoZ3PRKkis/bpu3N3Z/l0OVd+5nLPlfUYbUUiBDkRI+Ry/H1XDWxVvxd3/rtJp9L1exhBO3F94IkUUm7wuvWjPR1KYpY46bT6x00+Hj/7rWvS+V/vWmn6jc6we62UlHvJ62e6OyBZTOLM076N7uHR5/AP+weHn2CnqrxYS6D8Y0dVaoyrTPWhlYxIYOM/AJ0id7GgiBCMGqlE+4lG+2VHWR33m13caTWfKJ/73KDrB6dslZHS738vGench5shlSjR1W/wTqr+2NjmgBDugvt/GV5okaLzzPJb1H9XvQCVq2rtZ16/nWev6pKbNRPBDwPd9htwGviIuH2NGQKcshsTqvPkchua0dC1bX8cQfYxbjtvOerNhR28ozyfLAo0uaVdKnZ6DoZvSfbLDGEdM2OD+rItbbgmB8Y0K7DWJSzkvPKOj0P6bKzxBPS5JRzlHUQAGDtZuYiHBnTruuxkbA7NhaFf7N7ePQJ/MPu4dEn6Kkan83ksHpiAwCgOKjJAxJiNWr3k5raWCZ3OLFz3GgadV/s9NoKr9UZHuNgkxMRSiWtqm+bYJXqnb/2etUWC5KEhRaPMZTRHHG1Nqv4Geid18IoJ83cf//Dqq0pVMu9+0QlVdLq3OVv55JD/+uvdCmkLaeK3+9I0GcnpuKtTAwyzo+ctJsEl19Iekc/EuQVDaMWNyt8bRp1oWabyLWt65ls4Rf/86hqu/76f0hlSUpRq+id7g3ruDyWrZ7qHB9P8sft2T2j+oF4/OqCHt+1+N5p1/VOvWS/diLSM4BR1YX5Vi/vVW0kko2kSv8nf/BfVb9vfp9Lgq2aMNVqu+WxyJCUSPg3u4dHn8A/7B4efQL/sHt49Al6arM3GjU88NAdAIB9szpzadc+/hwbl9RZZ52VysVgcfdJQZQQHhzRmXPT93LZqKyI9qLqAdXv7b9+KY8fa/tP8nbX59hmd7G2/+JgWyrnBvQ8sllBsJjRyy9LNks33Mz8vapffvT8VK5M6yrZMzOvSOXhUeH2MxGLlRofi4b1HHPDbLPX6pKT3ZBKCvuybVydJKIPCyW2X+dNxprbyP0WIs1f31jgazNSZHt7tqXXuyJIIG0GHwJeY+n+CqDnmxGRh5Hhxw8z3NaODaFJlu+lnIjujI2LMW7xnoDZaoID7xFIsk9rfq9dy3MeHTb7VUlnzoTFbfbl1mffCaACIAbQds6dQ0TjAD4PYAuAnQDe4JxbnKHew8NjRfFU1PhXOOfOds6d0/38HgDbnXPbAGzvfvbw8HiG4ljU+EsAnN+Vr0WnBty7F+sMALVaFbfffisA4ImyVp9rVeHegI6Q2rp1SyqTKLuUZHU008g4q61RotWZJwRRBDlWKz/6h/o3KpcRfOc28UMwNNSrrOKPD2jV8eAsH8tynckkkzjQ48+X2TTICZX51h/ockGbN52TyudMav7wwhpWz/OCKKLR0OpnINxriameWpsX5YgCSRZiCDBiwXFuklMi4rZ2ns2EZOY7qt8vv41db/m1hk9PRDdSwuMNmSg2WU22VNLRb7t2c0mwiQl29xK0e60R8/dKoVbxa6Jk14jT5pBzfN5BEApZP1phhu/HKNLmYVskdElyj7ZJGlotqhS34rtUW+IOkVksTlKy3De7A/AvRHQ7EV3W/dsa59weAOj+v3rRb3t4eKw4lvtmf7FzbjcRrQZwPREtXnbCoPvjcBkAFHO9JbP18PBgLOvN7pzb3f1/P4CvADgXwD4imgKA7v/7F/nuNc65c5xz5+SXoLn18PA4sTjqq5aIBgAEzrlKV341gA8C+BqASwFc1f3/q0cbywFodZP9Ww1t5xYLbNuefIrmckeb+5aGRfjjmHYZSZvSumAqZbZZ//Lq30/lwZy2m+siNLIY6lDaOWmLixpoQwPGThI+iXbLuGASQXBg51gRNnueL03N+Go2P/uNqfyhd/2javvEn/N51kd5j2F8XNvUhSFeu8CkStXFfsrAkAizNaQLEG5Qey4k3JQQ+wWnP1fz6K856YpU3v7dP1Vt03uY3CPI8LrNzZl6bjm2xS2xxcAgfy6WeE3DwHLD8/iZnMlsk3XxTHh1W9xzsp/L6rUSlZ3hSO9JhaEgxWyKrE6nH89Sia9Zwzw/rVbnmiVO388Sy9Gr1wD4StfHmgHwWefcdUR0K4AvENFbATwO4BeWMZaHh8cK4agPu3PuEQDPPcLfpwFccCIm5eHhcfzR0x2z4dFRvOaSSwAAD/34Dj0RJ0oDm6iz3JBwbwyx+hU7k4Ul3FV5U255JMPujjGSWUxa7UmEqtrQ2hZioSKFIkLs53/+fNXvlqu5DPTvXvnHqu2d//VNqTw1qTP/GnVWJbM5VhdDQ7BRm/teKt/xyIv1JAsfT8XSMEekja7S/PgjE+w8sRzqe4RKG4hMN1sGm0K+LocRiUTlVN66niPe/vhqrSJTlm/B5rzOBmvW+ZoNjDMpR2BchUSC575tuN+ESu7aglxiQK99UajWlVjfV2GGTZlaS6vPbbHtNZSXx9LRnbEgs8gG2mySmXQiWA9h1kRYtvmejiJtTkTtjmnjrKkl4HfMPDz6BP5h9/DoE/iH3cOjT9BbpppsDmvXdJhq9g1qkkZpaxSGtA05IuzNiSnmzj64RzPaSNebJfX7yAffl8q1GruyrB0aiCwm2c+OWa+w+ydX0CGriWO78TOfuk61/fqlr0nlonHjhAHbwI0G23y2vtiNP/hcKr/sgk+ptk+9i+307TcKcksTPhwJezhvSApHBenmfIXtbVm+GQCaIjQzl9PnUtl/dyrPtnmPYfuj71T9dt73gVRemNGhGpJZJifCpNesWaP6JSK82ob0ykxCCRfo0tGUEySbTi+IHGNgRO85FESNuESEQudMaee6YPUJTDi4vb6HUKvpORZEaerWrH5G4mShO/cjDtU9roeHR1/AP+weHn2CnqrxQRCgUOioZuvXbVZtc3VWFwdGtdts1ZqNqRwJFciZUjdDeXaRWN743ABnxDXnmDfeqn01wZMuy/0CQKDKS7FcqWr1sxWx2rd5o87kihN2sxBpVU+qrXJalqSjUuZjP/7I36m2X/qjC1P5k+9kFf+7N+kx3NYzefy6zsLKi4ytQl5G0Ol3Q1jga2FV0W0ncRTeu/77xal8yiZtetWnpZkwotp27WIXpswGO4wbPpTZZnqOlng0Pa4550io4NWmKVEV8fFyOT3HRJSecmINWi19X0nSEhmt1xmTVXIZRZkd0iZDrV5O5XnDHNFsd1T+uO1dbx4efQ//sHt49Al6qsY7l6DdLe0UDuud3SFRZTQxalpCrIJmhZqWhdnNFjvphcKkaosdq05OJEQ0pnVSRavJqnu2qIknnFDF2kJdCs0qhoJooQmdmLFpM5svMwf1sfMiAmv/fjY1rDlRa7CX4JbvfVG1XfzLH0rlyz/0H1L5g7/5WdVvdg/z0s9XX6DaJiZ4jmHI16Ve1wQYseBXXz15j2r7i09yW2uSyzr946feovotzLPa2kpMcpRQ3aVZlivo6yK9JpbXLxGRjjKxacFU3gX4cy6jCTBmK6y6r6vra5HNCfVcbIUHgVbjpXLdMtF1TpCilETV3MTs2hfE/AcKOiLy4JNPdo4T+yquHh59D/+we3j0CfzD7uHRJ+i5zX6oPpgzvN1ZQa7XNgn4lWl24+RE6WXrZolF9tD6DeO6bZEoJZut1Wiy7VYqWheMmKOo5ZWNtR0XirpeYVFn8NVrPA/JDQ8Aq0TZahkxZl1N5XI5lU86SXOtX/fpP0jlc1/366l8xcdeq/r9yTv42FsmH1Btjz08msqBzDgMTZbhgnCX5vT+ww8fY/79nXcwD+neOX3Ocwc5SsxGPQ6LaLVcXu6X6H7SNTkyol1jmZiv78JMWbToNZ3euzOVB6fOVm133s/7J2dsMoQpItpOXqdMRu8ryPvMmTC3ULrsiuKRtPdVjvtNTU3pOe7o8PHH8eLkFf7N7uHRJ/APu4dHn6CnajwhQBh0VLMRHceP+Tq7gkLDfd0W7jDh1QKZKLlEJGNkjT8srrJ7poZyKtfjiuoXZERSRVOr/rEgLoiE+yQwZkdbuEiyRuXMFXjO4xNaJZTlhiWnm1XjxwWRw/S0LqfUavFa/d8v/o9UvvCiy1W/3/0Il6j6pZfq0tH//sIbU/nOe09L5aGcdknVK7el8jv+WEcRRg0uWfXAo3xtnYkanJ1hFXnCcA/OzpVTWUaZ2bLMMkHnsMQXEfXXaMq11+r+l7/0yVR+y29crdpuuZNJNf7j+TqqLZcRarw8rFGnY2G25k3kp6yTEDXZvVnMmwQr4e4dGhlTbQu1znWPk8UzYfyb3cOjT+Afdg+PPoF/2D08+gS9db0hSYkd2rEmhpDZZ7GxgUMRQhi0RVitKTqRF2GOsnYcAGSIbSFK2K5tmoyyXCBdPHqMlqjR1Wrr0E41huA4r8faBdNqsk1lbXH5WZJAWht1WJRYPnjwoGqTfPNRhe357df/hep3YJbn+Jtv/7hqG5/cmcpnTj2Uyj96UNu5r/xpQcS4/fWq7bvffXMqhwnPqTyjr/u6deuwGKQtLs9zyJCJykwxS7Ahw2ela8+G1T77rLWpTIbXPZdhl+ihPSceU9SjI5nZZsJlRcZks6ZdanIumdziJJ4kCDFsJuRy4N/sHh59Av+we3j0CXqsxgOtrmuATKBPErOanTdus1bEql8sVPV8aVT1k2oa6WQzNESJ5ZzIXoNRh9oiKi82k2wKF2BelM+1EVG5kFW2INS/p6vWbE3lxx+5W7XJrDKpjtrxZTSgVRed4CcnEb03Pa0j1ybG2H33o5v/WrW94CVXpvJf/gG70O754o9Uv9dc/HOpHGa0G7GU4QivXbs5Qm90RGcjzpc58i5reNuKeTZlaqLEtDO87hDuJltWLC8iAMfH2AwhE33ZqnNp50yg1ey6KE09t6DHL5R4nKgl3azabUvimtnIz7ZoywszVZb3BoCiKP9t+fEzXZOWFk96W96bnYhGiegfiOg+IrqXiF5IRONEdD0RPdj9f+zoI3l4eKwUlqvGfwzAdc65Z6FTCupeAO8BsN05tw3A9u5nDw+PZyiWU8V1GMDLALwZAJxzLQAtIroEwPndbtcCuAHAuw8fQSBJkNQ6O6dWDdFJBHpaQrNRql5kVNicrBza1CoQCa6wuiCDIEMyEIQ8j1pNR2Pli6xWLjXfRrOcyi7Q6m1emBeWJy8U6p2MoLM7zBJWjc+E3JeEKjkyrBODnKCtfviJR1TbE/uY+vk33ndyKv/FlTra8Nfe+rFU3tm6ULVlc/85lYeHWH22noW8UE3n5zV1sjxved0lqQWgzRpL9CHXR0bX2dJKIhAOSbRPtQViN/6ue/U98bIRXsdMyCZmbEtImSQfNcf2kZNXbPKWJOlowSbTdD8fI5X0SQAOAPg7IrqDiP66W7p5jXNuDwB0/1+91CAeHh4ri+U87BkAzwfwCefc8wBU8RRUdiK6jIhuI6Lb5hdqR/+Ch4fHCcFyHvZdAHY5527ufv4HdB7+fUQ0BQDd//cf6cvOuWucc+c4584ZHlxcHfXw8DixWE599r1E9AQRneacux+dmuz3dP9dCuCq7v9fPdpYSZygudBxLyUtbZ85QcxYrRs7Wtiy9VnxvZLJQBrmyKoYiyfxyxK/TWvbC3dbqaQ5xyORyURCDswqDoFJHWp0mmr7s7/8h1R+4dkbVdvq1aOpLN1L0q4FAOFdw+iAjiabmWdXlrRtC6ZEVW6JSK2H7v0XnuPr/jSVp0Y01/+69ey23HGH/q2X+ywZsb8xfUBH/G3atCmVretN2rnSnreuSLlnYu15eZ5yj2TXrl2qX0ms4zeu+yvV9tqf+/1Uvu4mnSH4My/mugCNhPc0MoH2/cpsRGu/Z8Q+USAeySAwEXQiG7Rm6ok3u246uzbqOIu2aPwXAJ8hohyARwD8GjpawReI6K0AHgfwC8scy8PDYwWwrIfdOXcngHOO0HTBcZ2Nh4fHCUNvI+iSBK0u73ZU1S6YMMdqlLPccsIFEQtXSinQZAokyi45G0EnXTJOJNMY15V0qR2WiCCSZGLi78lSUAAwNsJq2sKcNhOu+iN2V33ps1dhMchEB5kUA2i3XN64/SSv3VKkDpLHzvKZycitQsDHvuWxl6t+n/riV1K5UdAq/sIcEz60mryOS7nN7LWQ5pss42Sr68q2PXv2qDZpJkgV13LVSTXerndLHK8g3HAAMC+uRUHyzplINqm62yQWye3XrPLa2yi/gSLf1CXS937SPmQCLZ4g42PjPTz6BP5h9/DoE/iH3cOjT9Dbks1Eab2qTE67kxottlUGJ3Rop7I3BWFhIafDPHN0eio3obOTtC3OdqJ0zRw2X5udJAgIZHylycHCKSetSeW9t+vWVp3nIW1vQO8r5MW8LKnkoHAx1pvaRpuc5KwyaQ9bG1WOaW3Ig08wT/8NX7oilQ/U7lP9KsR7AkGkXWoLVXaVxTW7Qgxpp1u3kbTNl+LRl+cpufcBYPduJruUa2PtcnlPPPLIQ6ptbnpHKmenTldtcuWKgqQDJgxbnqd1MbZjEcYryEpzeT3H2TJfl9Ubtqq2IM0G9bzxHh59D/+we3j0CWipiJvjfjCiAwAeA7AKwMGjdO8F/Dw0/Dw0ngnzeKpz2OycmzxSQ08f9vSgRLc5544UpOPn4efh53GC5uDVeA+PPoF/2D08+gQr9bBfs0LHtfDz0PDz0HgmzOO4zWFFbHYPD4/ew6vxHh59gp4+7ER0ERHdT0QPEVHP2GiJ6G+JaD8R3S3+1nMqbCLaSETf6dJx7yCiK1ZiLkRUIKJbiOjH3Xl8YCXmIeYTdvkNv75S8yCinUT0EyK6k4huW8F5nDDa9p497NShh/k4gNcAOAPALxLRGUt/67jhkwAuMn9bCSrsNoB3OOdOB3AegLd316DXc2kCeKVz7rkAzgZwERGdtwLzOIQr0KEnP4SVmscrnHNnC1fXSszjxNG2O+d68g/ACwF8S3x+L4D39vD4WwDcLT7fD2CqK08BuL9XcxFz+CqAV63kXACUAPwIwAtWYh4ANnRv4FcC+PpKXRsAOwGsMn/r6TwADAN4FN29tOM9j16q8esBPCE+7+r+baWwolTYRLQFwPMA3LwSc+mqzneiQxR6vesQiq7EmnwUwLug84lWYh4OwL8Q0e1EdNkKzeOE0rb38mE/UhWqvnQFENEggC8B+C3n3PzR+p8IOOdi59zZ6LxZzyWiM3s9ByJ6HYD9zrnbe33sI+DFzrnno2Nmvp2IXrYCczgm2vajoZcP+y4Akk51A4Ddi/TtBZZFhX28QURZdB70zzjnvryScwEA51wZnWo+F63APF4M4GeJaCeAzwF4JRF9egXmAefc7u7/+wF8BcC5KzCPY6JtPxp6+bDfCmAbEW3tstS+EcDXenh8i6+hQ4ENLJMK+1hBnUTsvwFwr3Pu6pWaCxFNEtFoVy4C+BkA9/V6Hs659zrnNjjntqBzP3zbOfemXs+DiAaIaOiQDODVAO7u9Tycc3sBPEGU8o8fom0/PvM40RsfZqPhYgAPAHgYwJU9PO7fA9gDIELn1/OtACbQ2Rh6sPv/eA/m8RJ0TJe7ANzZ/Xdxr+cC4DkA7ujO424Av9/9e8/XRMzpfPAGXa/X4yQAP+7+23Ho3lyhe+RsALd1r80/Ahg7XvPwEXQeHn0CH0Hn4dEn8A+7h0efwD/sHh59Av+we3j0CfzD7uHRJ/APu4dHn8A/7B4efQL/sHt49An+H6uEt5WhlrfrAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试你的图片\n",
    "img = image.load_img('./klay.jpg', target_size=(64, 64))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(happy_model.predict(x=x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HappyModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 37,633\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "happy_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "----\n",
    "2 - 残差网络的搭建"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.python.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import resnets_utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    实现恒等块\n",
    "    Args:\n",
    "        X: 输入的tensor类型的数据，维度为(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        f: 整数，指定主路径中间的CONV窗口的维度\n",
    "        filters: 整数列表，定义了主路径每层的卷积层的过滤器数量\n",
    "        stage: 整数，根据每层的位置来命名每一层，与block参数一起使用。\n",
    "        block: 字符串，据每层的位置来命名每一层，与stage参数一起使用。\n",
    "\n",
    "    Returns:\n",
    "        X - 恒等块的输出，tensor类型，维度为(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # 定义命名规则\n",
    "    conv_name_base = \"res{}{}_branch\".format(stage,block)\n",
    "    bn_name_base = \"bn{}{}_branch\".format(stage,block)\n",
    "\n",
    "    # 获取过滤器数量\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # 保存输入数据，将会用于为主路径添加捷径\n",
    "    X_shortcut = X\n",
    "\n",
    "    # 主路径：1st part\n",
    "    ## conv layer\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ## BN layer\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    ## ReLU\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 主路径：2nd part\n",
    "    ## conv layer\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ## BN layer\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    ## ReLU\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 主路径：3rd part\n",
    "    ## conv layer\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ## BN layer\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "    ## no ReLU\n",
    "\n",
    "    # Finally\n",
    "    ## 将捷径与输入加在一起\n",
    "    X = Add()([X, X_shortcut])\n",
    "    ## ReLU\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.9482299 0.        1.1610144 2.747859  0.        1.36677  ]\n",
      "(3, 4, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder('float', shape=(3, 4, 4, 6))\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f=2, filters=[2, 4, 6], stage=1, block='a')\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    test.run(init)\n",
    "    out = test.run([A], feed_dict={A_prev: X,\n",
    "                                   K.learning_phase(): 0})\n",
    "    print(\"out = {}\".format(out[0][1][1][0]))\n",
    "    print(out[0].shape)\n",
    "    test.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**我们已经实现了残差网络的恒等块，现在，残差网络的卷积块是另一种类型的残差块，\n",
    "它适用于输入输出的维度不一致的情况，它不同于上面的恒等块，与之区别在于，\n",
    "捷径中有一个CONV2D层**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    实现卷积块\n",
    "    Args:\n",
    "        X: 输入的tensor类型的变量，维度为(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        f: 整数，指定主路径中间的CONV窗口的维度\n",
    "        filters: 整数列表，定义了主路径每层的卷积层的过滤器数量\n",
    "        stage: 整数，根据每层的位置来命名每一层，与block参数一起使用。\n",
    "        block: 字符串，据每层的位置来命名每一层，与stage参数一起使用。\n",
    "        s: 整数，指定要使用的步幅\n",
    "\n",
    "    Returns:\n",
    "        X - 卷积块的输出，tensor类型，维度为(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # 定义命名规则\n",
    "    conv_name_base = \"res{}{}_branch\".format(stage,block)\n",
    "    bn_name_base = \"bn{}{}_branch\".format(stage,block)\n",
    "\n",
    "    # 获取过滤器数量\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # 保存输入数据，将会用于为主路径添加捷径\n",
    "    X_shortcut = X\n",
    "\n",
    "    # 主路径：1st part\n",
    "    ## conv layer\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid',\n",
    "               name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ## BN layer\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
    "    ## ReLU\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 主路径：2nd part\n",
    "    ## conv layer\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ## BN layer\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    ## ReLU\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # 主路径：3rd part\n",
    "    ## conv layer\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ## BN layer\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "    ## no ReLU\n",
    "\n",
    "    # 捷径\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid',\n",
    "                        name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Finally\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.09018461 1.2348977  0.46822017 0.0367176  0.         0.655166  ]\n",
      "(3, 2, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "\n",
    "    A = convolutional_block(A_prev, f=2, filters=[2, 4, 6], stage=1, block=\"a\")\n",
    "    test.run(tf.global_variables_initializer())\n",
    "\n",
    "    out = test.run([A],feed_dict={A_prev: X,\n",
    "                                  K.learning_phase(): 0})\n",
    "    print(\"out = {}\".format(out[0][1][1][0]))\n",
    "    print(out[0].shape)\n",
    "    test.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64, 64, 3), classes=6):\n",
    "    \"\"\"\n",
    "    实现ResNet50\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Args:\n",
    "        input_shape: 图像数据集的维度\n",
    "        classes: int，分类数\n",
    "\n",
    "    Returns:\n",
    "        model - Keras框架的模型\n",
    "    \"\"\"\n",
    "\n",
    "    # 定义tensor类型的输入数据\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    #0填充\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # stage1\n",
    "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2),\n",
    "               name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # stage2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64, 64, 256], stage=2, block=\"c\")\n",
    "\n",
    "    # stage3\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128, 128, 512], stage=3, block=\"d\")\n",
    "\n",
    "    # stage4\n",
    "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, f=3, filters=[256, 256, 1024], stage=4, block=\"f\")\n",
    "\n",
    "    # stage5\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[512, 512, 2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[512, 512, 2048], stage=5, block=\"c\")\n",
    "\n",
    "    #输出层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    #创建模型\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"ResNet50\")\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64, 64, 3), classes=6)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = resnets_utils.load_dataset()\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = resnets_utils.convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = resnets_utils.convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples\n",
      "Epoch 1/2\n",
      "1080/1080 [==============================] - 10s 9ms/sample - loss: 5.0694 - acc: 0.2583\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/2\n",
      "1080/1080 [==============================] - 3s 3ms/sample - loss: 1.6265 - acc: 0.4685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x19f989801c8>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=2, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 11ms/sample - loss: 2.1325 - acc: 0.1667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "误差值 = 2.1324776728947956\n",
      "准确率 = 0.16666667\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"误差值 = \" + str(preds[0]))\n",
    "print(\"准确率 = \" + str(preds[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-26-95b76178fb9f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#加载模型\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"./ResNet50.h5\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001B[0m in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[0;32m    141\u001B[0m   if (h5py is not None and (\n\u001B[0;32m    142\u001B[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001B[1;32m--> 143\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mhdf5_format\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_model_from_hdf5\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcustom_objects\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    144\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstring_types\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001B[0m in \u001B[0;36mload_model_from_hdf5\u001B[1;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[0;32m    158\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mmodel_config\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m       \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'No model found in config file.'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 160\u001B[1;33m     \u001B[0mmodel_config\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_config\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'utf-8'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    161\u001B[0m     model = model_config_lib.model_from_config(model_config,\n\u001B[0;32m    162\u001B[0m                                                custom_objects=custom_objects)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "#加载模型\n",
    "model = load_model(\"./ResNet50.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 1ms/sample - loss: 2.1325 - acc: 0.1667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "误差值 = 2.1324776728947956\n",
      "准确率 = 0.16666667\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print(\"误差值 = \" + str(preds[0]))\n",
    "print(\"准确率 = \" + str(preds[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 15, 15, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 15, 15, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 15, 15, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 15, 15, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 15, 15, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 15, 15, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 15, 15, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 15, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 15, 15, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 15, 15, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 1024)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 2, 2, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Dense)                     (None, 6)            49158       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,636,870\n",
      "Trainable params: 23,583,750\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}